{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "documentation: https://github.com/microsoft/FLAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the logging level\n",
    "You can configure the logging level to suppress unnecessary outputs to keep the logs cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    " \n",
    "logging.getLogger('synapse.ml').setLevel(logging.CRITICAL)\n",
    "logging.getLogger('mlflow.utils').setLevel(logging.CRITICAL)\n",
    "warnings.simplefilter('ignore', category=FutureWarning)\n",
    "warnings.simplefilter('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up MLflow experiment tracking\n",
    "<!-- MLflow is an open source platform that is deeply integrated into the Data Science experience in Fabric and allows to easily track and compare the performance of different models and experiments without the need for manual tracking. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/04 17:41:45 INFO mlflow.tracking.fluent: Experiment with name 'automl-tutorial' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/derne/OneDrive%20-%20The%20Pennsylvania%20State%20University/Programming/Git/AutoML%20App/AutoML%20tut/Flaml/mlruns/348856216409950599', creation_time=1728078105707, experiment_id='348856216409950599', last_update_time=1728078105707, lifecycle_stage='active', name='automl-tutorial', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Set the MLflow experiment to \"automl-tutorial\" and enable automatic logging\n",
    "mlflow.set_experiment(\"automl-tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MolLogP</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>NumRotatableBonds</th>\n",
       "      <th>AromaticProportion</th>\n",
       "      <th>logS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5954</td>\n",
       "      <td>167.850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.3765</td>\n",
       "      <td>133.405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5938</td>\n",
       "      <td>167.850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0289</td>\n",
       "      <td>133.405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.9189</td>\n",
       "      <td>187.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MolLogP    MolWt  NumRotatableBonds  AromaticProportion  logS\n",
       "0   2.5954  167.850                0.0                 0.0 -2.18\n",
       "1   2.3765  133.405                0.0                 0.0 -2.00\n",
       "2   2.5938  167.850                1.0                 0.0 -1.74\n",
       "3   2.0289  133.405                1.0                 0.0 -1.48\n",
       "4   2.9189  187.375                1.0                 0.0 -3.04"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv')\n",
    "X = df.drop('logS', axis=1)\n",
    "y = df['logS']\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have your features in X and target variable in y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      MolLogP    MolWt  NumRotatableBonds  AromaticProportion\n",
       " 643   3.61260  296.410                0.0            0.272727\n",
       " 722   6.48760  226.448               13.0            0.000000\n",
       " 570   3.15380  284.746                1.0            0.600000\n",
       " 66    0.77880   74.123                2.0            0.000000\n",
       " 1002  1.82140  102.177                3.0            0.000000\n",
       " ...       ...      ...                ...                 ...\n",
       " 1044  2.82960  253.305                1.0            0.631579\n",
       " 1095  2.10750  218.322                3.0            0.000000\n",
       " 1130  4.14820  335.282                7.0            0.260870\n",
       " 860   4.25720  275.179                4.0            0.352941\n",
       " 1126  6.25676  368.369                6.0            0.692308\n",
       " \n",
       " [915 rows x 4 columns],\n",
       "       MolLogP    MolWt  NumRotatableBonds  AromaticProportion\n",
       " 218   1.55740  102.177                3.0            0.000000\n",
       " 809   5.20590  345.653                4.0            0.571429\n",
       " 501   4.18090  339.218                4.0            0.545455\n",
       " 649   2.05760  286.349                4.0            0.315789\n",
       " 323   0.72822  146.153                0.0            0.909091\n",
       " ...       ...      ...                ...                 ...\n",
       " 361  -0.50840   59.068                0.0            0.000000\n",
       " 292   1.94750  116.204                3.0            0.000000\n",
       " 1119  2.16090  257.437                3.0            0.000000\n",
       " 557   3.36680  138.254                0.0            0.000000\n",
       " 448   1.40120  108.966                0.0            0.000000\n",
       " \n",
       " [229 rows x 4 columns],\n",
       " 643    -4.300\n",
       " 722    -8.400\n",
       " 570    -3.754\n",
       " 66      0.000\n",
       " 1002   -1.340\n",
       "         ...  \n",
       " 1044   -3.324\n",
       " 1095   -1.620\n",
       " 1130   -5.680\n",
       " 860    -4.770\n",
       " 1126   -6.010\n",
       " Name: logS, Length: 915, dtype: float64,\n",
       " 218    -0.890\n",
       " 809    -6.890\n",
       " 501    -4.530\n",
       " 649    -3.420\n",
       " 323    -0.466\n",
       "         ...  \n",
       " 361     1.580\n",
       " 292    -0.980\n",
       " 1119   -0.220\n",
       " 557    -5.190\n",
       " 448    -1.090\n",
       " Name: logS, Length: 229, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Classification Model with Flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "# automl.fit(X_train, y_train, task=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"time_budget\": 120,  # total running time in seconds\n",
    "    \"metric\": 'accuracy',  # check the documentation for options of metrics (https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#optimization-metric)\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"seed\": 42,    # random seed\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 10-04 17:42:29] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 10-04 17:42:29] {1739} INFO - Evaluation method: cv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 10-04 17:42:35] {1838} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 10-04 17:42:35] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']\n",
      "[flaml.automl.logger: 10-04 17:42:35] {2258} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 10-04 17:42:38] {2393} INFO - Estimated sufficient time budget=34389s. Estimated necessary time budget=796s.\n",
      "[flaml.automl.logger: 10-04 17:42:38] {2442} INFO -  at 9.5s,\testimator lgbm's best error=0.2451,\tbest estimator lgbm's best error=0.2451\n",
      "[flaml.automl.logger: 10-04 17:42:38] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 10-04 17:42:42] {2442} INFO -  at 13.9s,\testimator lgbm's best error=0.2451,\tbest estimator lgbm's best error=0.2451\n",
      "[flaml.automl.logger: 10-04 17:42:42] {2258} INFO - iteration 2, current learner sgd\n",
      "[flaml.automl.logger: 10-04 17:43:45] {2442} INFO -  at 76.5s,\testimator sgd's best error=0.9981,\tbest estimator lgbm's best error=0.2451\n",
      "[flaml.automl.logger: 10-04 17:43:45] {2258} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 10-04 17:43:49] {2442} INFO -  at 80.7s,\testimator lgbm's best error=0.2451,\tbest estimator lgbm's best error=0.2451\n",
      "[flaml.automl.logger: 10-04 17:43:49] {2258} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 10-04 17:43:55] {2442} INFO -  at 86.2s,\testimator xgboost's best error=0.4005,\tbest estimator lgbm's best error=0.2451\n",
      "[flaml.automl.logger: 10-04 17:43:55] {2258} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 10-04 17:44:07] {2442} INFO -  at 98.0s,\testimator lgbm's best error=0.1521,\tbest estimator lgbm's best error=0.1521\n",
      "[flaml.automl.logger: 10-04 17:44:07] {2258} INFO - iteration 6, current learner extra_tree\n",
      "[flaml.automl.logger: 10-04 17:44:07] {2442} INFO -  at 98.5s,\testimator extra_tree's best error=0.9652,\tbest estimator lgbm's best error=0.1521\n",
      "[flaml.automl.logger: 10-04 17:44:07] {2258} INFO - iteration 7, current learner extra_tree\n",
      "[flaml.automl.logger: 10-04 17:44:08] {2442} INFO -  at 99.3s,\testimator extra_tree's best error=0.9481,\tbest estimator lgbm's best error=0.1521\n",
      "[flaml.automl.logger: 10-04 17:44:08] {2258} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 10-04 17:44:12] {2442} INFO -  at 103.3s,\testimator lgbm's best error=0.1521,\tbest estimator lgbm's best error=0.1521\n",
      "[flaml.automl.logger: 10-04 17:44:12] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 10-04 17:44:29] {2442} INFO -  at 120.9s,\testimator lgbm's best error=0.1445,\tbest estimator lgbm's best error=0.1445\n",
      "[flaml.automl.logger: 10-04 17:44:38] {2685} INFO - retrain lgbm for 9.0s\n",
      "[flaml.automl.logger: 10-04 17:44:38] {2688} INFO - retrained model: LGBMClassifier(colsample_bytree=0.8871559629536413,\n",
      "               learning_rate=0.08570310532994721, max_bin=63,\n",
      "               min_child_samples=12, n_estimators=1, n_jobs=-1, num_leaves=4,\n",
      "               reg_alpha=0.02960826033957992, reg_lambda=0.512318588788703,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 10-04 17:44:38] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 10-04 17:44:38] {1986} INFO - Time taken to find the best model: 120.9307713508606\n"
     ]
    }
   ],
   "source": [
    "'''The main flaml automl API'''\n",
    "# with mlflow.start_run(run_name=\"flight_delays_baseline\"):\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ML leaner: lgbm\n",
      "Best hyperparmeter config: {'n_estimators': 49, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.08570310532994721, 'log_max_bin': 6, 'colsample_bytree': 0.8871559629536413, 'reg_alpha': 0.02960826033957992, 'reg_lambda': 0.512318588788703}\n",
      "Best accuracy on validation data: 0.8555\n",
      "Training duration of best run: 9.012 s\n"
     ]
    }
   ],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model saving and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'flight_delays_baseline'.\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Run 'None' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mautoml\u001b[38;5;241m.\u001b[39mbest_run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Register the model to the MLflow registry\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m registered_model \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mregister_model(model_uri\u001b[38;5;241m=\u001b[39mmodel_path, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflight_delays_baseline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the registered model's name and version\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registered successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\derne\\.conda\\envs\\envWEB\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:77\u001b[0m, in \u001b[0;36mregister_model\u001b[1;34m(model_uri, name, await_registration_for, tags)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_model\u001b[39m(\n\u001b[0;32m     18\u001b[0m     model_uri,\n\u001b[0;32m     19\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelVersion:\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m        Version: 1\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _register_model(\n\u001b[0;32m     78\u001b[0m         model_uri\u001b[38;5;241m=\u001b[39mmodel_uri, name\u001b[38;5;241m=\u001b[39mname, await_registration_for\u001b[38;5;241m=\u001b[39mawait_registration_for, tags\u001b[38;5;241m=\u001b[39mtags\n\u001b[0;32m     79\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\derne\\.conda\\envs\\envWEB\\Lib\\site-packages\\mlflow\\tracking\\_model_registry\\fluent.py:108\u001b[0m, in \u001b[0;36m_register_model\u001b[1;34m(model_uri, name, await_registration_for, tags, local_model_path)\u001b[0m\n\u001b[0;32m    106\u001b[0m source \u001b[38;5;241m=\u001b[39m model_uri\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mis_runs_uri(model_uri):\n\u001b[1;32m--> 108\u001b[0m     source \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(model_uri)\n\u001b[0;32m    109\u001b[0m     (run_id, _) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(model_uri)\n\u001b[0;32m    111\u001b[0m create_version_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_create_model_version(\n\u001b[0;32m    112\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    113\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m     local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n\u001b[0;32m    118\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\derne\\.conda\\envs\\envWEB\\Lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:39\u001b[0m, in \u001b[0;36mRunsArtifactRepository.get_underlying_uri\u001b[1;34m(runs_uri)\u001b[0m\n\u001b[0;32m     37\u001b[0m (run_id, artifact_path) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(runs_uri)\n\u001b[0;32m     38\u001b[0m tracking_uri \u001b[38;5;241m=\u001b[39m get_databricks_profile_uri_from_artifact_uri(runs_uri)\n\u001b[1;32m---> 39\u001b[0m uri \u001b[38;5;241m=\u001b[39m get_artifact_uri(run_id, artifact_path, tracking_uri)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mis_runs_uri(uri)  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m add_databricks_profile_info_to_artifact_uri(uri, tracking_uri)\n",
      "File \u001b[1;32mc:\\Users\\derne\\.conda\\envs\\envWEB\\Lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:52\u001b[0m, in \u001b[0;36mget_artifact_uri\u001b[1;34m(run_id, artifact_path, tracking_uri)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     47\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA run_id must be specified in order to obtain an artifact uri!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m     49\u001b[0m     )\n\u001b[0;32m     51\u001b[0m store \u001b[38;5;241m=\u001b[39m _get_store(tracking_uri)\n\u001b[1;32m---> 52\u001b[0m run \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mget_run(run_id)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Maybe move this method to RunsArtifactRepository so the circular dependency is clearer.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlparse(run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39martifact_uri)\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\derne\\.conda\\envs\\envWEB\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:693\u001b[0m, in \u001b[0;36mFileStore.get_run\u001b[1;34m(self, run_id)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03mNote: Will get both active and deleted runs.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m _validate_run_id(run_id)\n\u001b[1;32m--> 693\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info(run_id)\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m metadata is in invalid state.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    697\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mINVALID_STATE,\n\u001b[0;32m    698\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\derne\\.conda\\envs\\envWEB\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:718\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[1;34m(self, run_uuid)\u001b[0m\n\u001b[0;32m    716\u001b[0m exp_id, run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_run_root(run_uuid)\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[0;32m    720\u001b[0m     )\n\u001b[0;32m    721\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info_from_dir(run_dir)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "\u001b[1;31mMlflowException\u001b[0m: Run 'None' not found"
     ]
    }
   ],
   "source": [
    "model_path = f\"runs:/{automl.best_run_id}/model\"\n",
    "\n",
    "# Register the model to the MLflow registry\n",
    "registered_model = mlflow.register_model(model_uri=model_path, name=\"flight_delays_baseline\")\n",
    "\n",
    "# Print the registered model's name and version\n",
    "print(f\"Model '{registered_model.name}' version {registered_model.version} registered successfully.\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'registered_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregistered_model\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted labels\u001b[39m\u001b[38;5;124m'\u001b[39m, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'registered_model' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.sklearn.load_model(f\"models:/{registered_model.name}/{registered_model.version}\")\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print('Predicted labels', y_pred)\n",
    "print('True labels', y_test)\n",
    "y_pred_proba = automl.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' compute different metric values on testing dataset'''\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test.astype(float)))\n",
    "print('roc_auc', '=', 1 - sklearn_metric_loss_score('roc_auc', y_pred_proba, y_test.astype(float)))\n",
    "print('log_loss', '=', sklearn_metric_loss_score('log_loss', y_pred_proba, y_test.astype(float)))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 10-04 17:15:55] {1728} INFO - task = classification\n",
      "[flaml.automl.logger: 10-04 17:15:55] {1739} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 10-04 17:16:02] {1838} INFO - Minimizing error metric: log_loss\n",
      "[flaml.automl.logger: 10-04 17:16:02] {1861} WARNING - No search budget is provided via time_budget or max_iter. Training only one model per estimator. Zero-shot AutoML is used for certain tasks and estimators. To tune hyperparameters for each estimator, please provide budget either via time_budget or max_iter.\n",
      "[flaml.automl.logger: 10-04 17:16:02] {1955} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
      "[flaml.automl.logger: 10-04 17:16:34] {2685} INFO - retrain lgbm for 31.6s\n",
      "[flaml.automl.logger: 10-04 17:16:34] {2688} INFO - retrained model: LGBMClassifier(colsample_bytree=0.6103565306428956,\n",
      "               learning_rate=0.10182098014295998, max_bin=31,\n",
      "               min_child_samples=21, n_estimators=1, n_jobs=-1, num_leaves=225,\n",
      "               reg_alpha=0.0009765625, reg_lambda=40.413729576022625,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 10-04 17:16:34] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 10-04 17:16:34] {1986} INFO - Time taken to find the best model: 0\n"
     ]
    }
   ],
   "source": [
    "#  restrict the learners and use FLAML as a fast hyperparameter tuning tool for XGBoost, LightGBM, Random Forest etc\n",
    "automl.fit(X_train, y_train, task=\"classification\", estimator_list=[\"lgbm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run generic hyperparameter tuning for a custom function.\n",
    "\n",
    "from flaml import tune\n",
    "tune.run(evaluation_function, config={…}, low_cost_partial_config={…}, time_budget_s=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envWEB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
